<h1>The Future of Artificial Intelligence</h1>

<h4> My thoughts on a recent <a href scrc ="http://www.wsj.com/articles/whats-next-for-artificial-intelligence-1465827619?href="/>Wall Street Journal</a> article</h4>

<p>After reading the article "Whatâ€™s Next for Artificial Intelligence" from the Wall Street Journal, several issues mentioned are worth pondering; both from a micro and a macro sense.  The article compiled the thoughts of four leaders the tech industry.  They voiced their enthusiasm and concern regarding the unknowable future of artificial intelligence.</p>

<p>he views that I found the most fascinating were those offered by Andrew Ng, the chief scientist at Biadu.  He focused on the economic ramifications of autonomous vehicles, specifically.  He predicts that millions of truck drivers will be replaced by faster, safer, and more efficient driverless versions in the very near future.  He likened this shift to when America went from a primarily agrarian society to an industrial one.  As a former teacher, I question whether our educational system is doing enough to prepare current students for these inevitable changes.  Are we preparing our students for jobs that do not yet exist?</p>

<p>The other fascinating aspect of the article dealt with the aspect of control.  How can we ensure that the machines will not turn against us?  Artificial Intelligence can do incredible things, but in the worst case scenario, it could also bring about human extinction.  Luke Nosek, from PayPal and Founders Fund, directly compares these issues to the ones faced by the previous generation with nuclear technology. Nuclear warfare could wipeout the planet, but it has also had immense benefits in the energy and medical fields, to name a few.  A professor form Oxford University, Nick Bostom's answer for proper control is to setup a proper goal system.  He envisions machines that will be able to learn human values.  My biggest issue, is one that he is also quick to point out - every human has differing values to some extent.  Taking a look at the 2016 political landscape, it is easy to see that values of Americans differ immensely, not to mention the values from others from different cultures.  Is there anything that we can all agree on?</p>

<p>The biggest question I have after reading this article is the notion regulation.  Is there anything that is already in place to address these concerns?  Who is going to write the rules?  How are a companies/countries going to be held accountable to ensure the doomsday scenarios mentioned in the article never occur?  Are we going to trust leaders to have enough common sense or is there a need for a regulatory body?</p>



<ul>
	<li>Pages</li>
		<ul>
			<li><a href="index.html">Home</a></li>
			<li><a href="Personal Goals.html">Goals</a></li>
			<li><a href="Bucket List.html">My Bucket List</a></li>
		</ul>

	<li>Articles</li>
		<ul>
			<li> The Future of Artificial Intelligence</li>
		</ul>

	<li>My Profiles</li>
		<ul>
			<li><a href="https://twitter.com">Twitter</a></li>
			<li><a href="https://github.com/mhughes27">GitHub</a></li>
			<li><a href="https://www.linkedin.com/profile/guided?trk=uno-choose-ge-no-intent&dl=no">LinkedIn</a></li>
</ul>
